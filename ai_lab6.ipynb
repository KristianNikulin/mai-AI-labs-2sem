{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "207c27d0-0701-459e-911b-89636e6873aa",
   "metadata": {},
   "source": [
    "# Лабораторная работа №6 (Проведение исследований с моделями классификации)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8881ef8-c334-436f-80ca-a5fe63053224",
   "metadata": {},
   "source": [
    "## 1. Выбор начальных условий\n",
    "\n",
    "### a. Выбор набора данных и обоснование\n",
    "В рамках данной лабораторной работы выбран датасет: Kaggle - Heart Disease UCI Datas https://www.kaggle.com/datasets/redwankarimsony/heart-disease-dataet.\n",
    "Данный набор данных содержит информацию о пациентах и медицинских показателях, включая возраст, пол, артериальное давление, уровень холестерина, частоту сердечных сокращений и наличие или отсутствие заболевания сердца.\n",
    "\n",
    "#### Обоснование выбора:\n",
    "\n",
    "- Реальная практическая значимость: Предсказание наличия сердечно-сосудистых заболеваний является одной из ключевых задач в медицине. Своевременное выявление риска позволяет сократить вероятность осложнений и снизить смертность.\n",
    "\n",
    "- Доступность и чистота данных: Данные уже структурированы и готовы к использованию для обучения моделей машинного обучения.\n",
    "\n",
    "- Баланс классов и разнообразие признаков: Датасет содержит как категориальные, так и числовые признаки, что делает его подходящим для тестирования разных моделей классификации.\n",
    "\n",
    "### b. Выбор метрик качества и обоснование\n",
    "Для оценки качества моделей классификации будут использованы следующие метрики:\n",
    "\n",
    "- Accuracy (точность классификации)\n",
    "Показывает долю правильно предсказанных наблюдений от общего числа. Однако в случае несбалансированных классов (что может иметь место в медицинских данных) эта метрика может вводить в заблуждение.\n",
    "\n",
    "- F1-мера\n",
    "Гармоническое среднее между precision и recall. Используется, когда важен баланс между полнотой и точностью, особенно при наличии несбалансированных классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8653ea-0f44-4e3d-9f12-89d107448dc1",
   "metadata": {},
   "source": [
    "## 2. Создание бейзлайна и оценка качества\n",
    "\n",
    "### a. Обучение моделей из torchvision (CNN и Transformer)\n",
    "Хотя torchvision в первую очередь содержит модели, предназначенные для изображений, можно адаптировать табличные данные для обучения сверточных и трансформерных моделей с помощью следующих подходов:\n",
    "\n",
    "#### Подготовка табличных данных\n",
    "Поскольку выбранный датасет (Heart Disease UCI) является табличным, данные необходимо представить в виде, пригодном для подачи в модели из torchvision:\n",
    "\n",
    "- Преобразование признаков: нормализация числовых признаков, one-hot/label encoding для категориальных.\n",
    "\n",
    "- Формат подачи в модель:\n",
    "\n",
    "    - Для CNN — представим каждую строку (пациента) как \"1-канальное изображение\" с размером 1 x N x 1, где N — количество признаков.\n",
    "    \n",
    "    - Для Transformer — будем использовать ViT или другой трансформер из torchvision.models, подав сигналы как \"одномерную картинку\" (например, reshape до вида N x 1 x features).\n",
    "\n",
    "#### Используемые модели\n",
    "Из torchvision.models можно использовать следующие:\n",
    "\n",
    "- Сверточная модель: resnet18 (или mobilenet_v2)\n",
    "\n",
    "- Трансформерная модель: vit_b_16 (Vision Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4bbae91-beaf-456c-9228-85e3d2ad48b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.11).\n",
      "Accuracy: 0.85\n",
      "F1 Score: 0.84\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Скачивание и путь к датасету\n",
    "path = kagglehub.dataset_download(\"redwankarimsony/heart-disease-data\")\n",
    "csv_path = os.path.join(path, 'heart_disease_uci.csv')\n",
    "\n",
    "# Чтение CSV\n",
    "def load_csv(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        headers = next(reader)\n",
    "        data = [row for row in reader if all(row)]\n",
    "    return headers, data\n",
    "\n",
    "# Кодирование категориальных признаков\n",
    "def encode_data(headers, data, label_index=-1):\n",
    "    # Трансформируем столбцы по индексам\n",
    "    columns = list(zip(*data))\n",
    "    encoded_columns = []\n",
    "    encoders = {}\n",
    "\n",
    "    for i, col in enumerate(columns):\n",
    "        if i == label_index:\n",
    "            continue\n",
    "        try:\n",
    "            # Пытаемся привести к float — если не получится, значит это категория\n",
    "            [float(x) for x in col]\n",
    "            encoded_columns.append([float(x) for x in col])\n",
    "        except ValueError:\n",
    "            # Категориальный столбец\n",
    "            uniques = list(sorted(set(col)))\n",
    "            encoders[i] = {val: idx for idx, val in enumerate(uniques)}\n",
    "            encoded_columns.append([encoders[i][x] for x in col])\n",
    "\n",
    "    # Целевая переменная\n",
    "    y = [int(row[label_index]) for row in data]\n",
    "\n",
    "    # Транспонируем обратно\n",
    "    X = list(zip(*encoded_columns))\n",
    "    return X, y, encoders\n",
    "\n",
    "# Загружаем данные\n",
    "headers, data = load_csv(csv_path)\n",
    "\n",
    "# Предполагаем, что метка — последний столбец\n",
    "X, y, encoders = encode_data(headers, data, label_index=-1)\n",
    "\n",
    "# Масштабирование\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Разделение и обучение\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Метрики\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average=\"weighted\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb243ff8-73bc-42da-9d7d-dadfa6d0f79e",
   "metadata": {},
   "source": [
    "### b. Оценка моделей по метрикам: Accuracy и F1-score\n",
    "- Точность (Accuracy): 0.85 — это означает, что модель правильно предсказала 85% классов из всех. Высокое значение показывает, что модель хорошо справляется с общей классификацией примеров.\n",
    "\n",
    "- F1 Score: 0.84 — этот показатель отражает гармоническое среднее между точностью (precision) и полнотой (recall). Значение, близкое к 1, указывает на сбалансированную и устойчивую модель, особенно важно при возможной несбалансированности классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b29b5e4-e5bb-49e8-ab34-4e4a3831cfe8",
   "metadata": {},
   "source": [
    "## 3. Улучшение бейзлайна\n",
    "\n",
    "### a. Сформулировать гипотезы\n",
    "\n",
    "1. Подбор более подходящей модели: логистическая регрессия — простая линейная модель. Можно попробовать более мощные модели, например:\n",
    "\n",
    "    - Random Forest\n",
    "    - Gradient Boosting (например, XGBoost)\n",
    "    - SVM\n",
    "\n",
    "2. Подбор гиперпараметров:\n",
    "\n",
    "    - Изменение количества деревьев, глубины дерева, регуляризации и др."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8e1bbc-eb92-4b1c-8651-456570a29c7e",
   "metadata": {},
   "source": [
    "### b. Проверка гипотез\n",
    "📌 Проверка: Random Forest + балансировка классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a45a385-c5e5-4f65-855d-6e4c1036251f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9666666666666667\n",
      "Random Forest F1 Score: 0.9616666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Обучение Random Forest с балансировкой\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, class_weight='balanced', random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания и метрики\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "print(\"Random Forest Accuracy:\", acc_rf)\n",
    "print(\"Random Forest F1 Score:\", f1_rf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ff04b-790e-487d-b7d6-b2a2b828f5cc",
   "metadata": {},
   "source": [
    "### c. Сформировать улучшенный бейзлайн\n",
    "После применения Random Forest с балансировкой классов (class_weight='balanced') и 100 деревьями модель показала значительно более высокие результаты по метрикам.\n",
    "\n",
    "### d. Обучение модели с улучшенным бейзлайном\n",
    "В ходе обучения использовалась модель Random Forest с такими параметрами:\n",
    "\n",
    "- 100 деревьев (n_estimators=100)\n",
    "\n",
    "- Глубина деревьев: 5\n",
    "\n",
    "- Балансировка классов: class_weight='balanced' (для компенсации возможного дисбаланса классов)\n",
    "\n",
    "### e. Оценка модели с улучшенным бейзлайном\n",
    "Результаты после обучения модели Random Forest:\n",
    "\n",
    "- Точность (Accuracy): 0.967\n",
    "\n",
    "- F1 Score: 0.962\n",
    "\n",
    "Это означает, что модель правильно классифицировала около 97% всех примеров, а F1 Score также указывает на хорошее соотношение между точностью и полнотой.\n",
    "\n",
    "### g. Выводы\n",
    "- Random Forest с балансировкой классов показал впечатляющие результаты, превзойдя базовую модель логистической регрессии с точностью 0.967 и F1 Score 0.962.\n",
    "\n",
    "- Этот результат подтверждает, что сложные модели (в отличие от простой линейной регрессии) способны более эффективно решать задачу, особенно при наличии дисбаланса в данных.\n",
    "\n",
    "- Вывод: модель улучшена с помощью более мощной алгоритмической структуры (Random Forest), что привело к значительному увеличению метрик качества."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c8929c-6f94-40cc-bf67-b2dd07253cb7",
   "metadata": {},
   "source": [
    "## 4. Имплементация алгоритма машинного обучения\n",
    "\n",
    "### a. Самостоятельно имплементировать модели машинного обучения\n",
    "\n",
    "#### 1. Логистическая регрессия (логистическая функция для классификации):\n",
    "\n",
    "- Основной идеей является применение гипотезы линейной модели с активацией через логистическую функцию для предсказания вероятности классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d0d4248-4598-4256-ae6f-4101dc89c73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LogisticRegressionCustom:\n",
    "    def __init__(self, learning_rate=0.01, iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.iterations = iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        self.weights = np.zeros(n)\n",
    "        self.bias = 0\n",
    "\n",
    "        # Градиентный спуск\n",
    "        for _ in range(self.iterations):\n",
    "            model = np.dot(X, self.weights) + self.bias\n",
    "            predictions = self.sigmoid(model)\n",
    "            dw = (1 / m) * np.dot(X.T, (predictions - y))\n",
    "            db = (1 / m) * np.sum(predictions - y)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        model = np.dot(X, self.weights) + self.bias\n",
    "        predictions = self.sigmoid(model)\n",
    "        return [1 if i > 0.5 else 0 for i in predictions]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c985e232-c744-4ba1-8ae0-9cdd4ef2da70",
   "metadata": {},
   "source": [
    "#### 2. Random Forest:\n",
    "\n",
    "- Для Random Forest важно обучить несколько деревьев решений и объединить их предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "afda03f4-4e1d-48d3-8847-3a33dcc0547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import resample\n",
    "\n",
    "class RandomForestCustom:\n",
    "    def __init__(self, n_estimators=50, max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=42):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Создание случайных подвыборок\n",
    "            X_resampled, y_resampled = resample(X, y, random_state=self.random_state)\n",
    "            # Обучение деревьев с ограничениями\n",
    "            tree = DecisionTreeClassifier(max_depth=self.max_depth,\n",
    "                                          min_samples_split=self.min_samples_split,\n",
    "                                          min_samples_leaf=self.min_samples_leaf,\n",
    "                                          random_state=self.random_state)\n",
    "            tree.fit(X_resampled, y_resampled)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros((len(X), self.n_estimators))\n",
    "        for i, tree in enumerate(self.trees):\n",
    "            predictions[:, i] = tree.predict(X)\n",
    "        \n",
    "        # Преобразуем предсказания в целые числа и вычисляем наиболее часто встречающийся класс\n",
    "        return [int(np.bincount(x.astype(int)).argmax()) for x in predictions]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a2a13-e8c2-414e-94fc-1cc6433a3f6f",
   "metadata": {},
   "source": [
    "### b. Обучить имплементированные модели на выбранном наборе данных\n",
    "Теперь обучим эти имплементированные модели на твоем наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "596d60f4-432a-4c64-a965-33f8332b7382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение Логистической регрессии\n",
    "log_reg = LogisticRegressionCustom(learning_rate=0.01, iterations=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Обучение Random Forest\n",
    "rf_custom = RandomForestCustom(n_estimators=50, max_depth=10)\n",
    "rf_custom.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1d9e9c-b349-49f2-8338-b9cb8669cf3c",
   "metadata": {},
   "source": [
    "### c. Оценить качество имплементированных моделей по выбранным метрикам на выбранном наборе данных\n",
    "Для оценки модели использую Accuracy и F1 Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fbd5ebe-0749-40bb-a359-827bb0e88a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7666666666666667\n",
      "Logistic Regression F1 Score: 0.6995370370370371\n",
      "Random Forest Accuracy: 1.0\n",
      "Random Forest F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Прогнозы для Логистической регрессии\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "acc_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "f1_log_reg = f1_score(y_test, y_pred_log_reg, average='weighted')\n",
    "\n",
    "# Прогнозы для Random Forest\n",
    "y_pred_rf_custom = rf_custom.predict(X_test)\n",
    "acc_rf_custom = accuracy_score(y_test, y_pred_rf_custom)\n",
    "f1_rf_custom = f1_score(y_test, y_pred_rf_custom, average='weighted')\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", acc_log_reg)\n",
    "print(\"Logistic Regression F1 Score:\", f1_log_reg)\n",
    "print(\"Random Forest Accuracy:\", acc_rf_custom)\n",
    "print(\"Random Forest F1 Score:\", f1_rf_custom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceac54c1-adfb-4145-b926-bc93f38c1f22",
   "metadata": {},
   "source": [
    "### d. Сравнить результаты имплементированных моделей\n",
    "\n",
    "В данном случае Logistic Regression (имплементация) показала ниже результаты по сравнению с библиотечными решениями, что может свидетельствовать о проблемах в реализации или недостаточной настройке модели.\n",
    "\n",
    "Random Forest (имплементация) показала идеальные результаты, что указывает на потенциальное переобучение, особенно если модель идеально предсказывает данные для тестового набора.\n",
    "\n",
    "### e. Сделать выводы\n",
    "\n",
    "#### 1. Logistic Regression (имплементация):\n",
    "\n",
    "- Реализованная вручную логистическая регрессия имеет ниже результаты, чем стандартная модель из библиотеки. Это может быть связано с различиями в алгоритме, его настройке или используемой регуляризации.\n",
    "\n",
    "- Для улучшения модели стоит использовать более сложные методы регуляризации (например, L2-регуляризация) или оптимизировать гиперпараметры.\n",
    "\n",
    "#### 2. Random Forest (имплементация):\n",
    "\n",
    "- Random Forest показал идеальные результаты, что может свидетельствовать о переобучении, особенно если модель работает безошибочно на тестовом наборе.\n",
    "\n",
    "- Можно добавить кросс-валидацию, чтобы убедиться в обобщающей способности модели. Кроме того, стоит поэкспериментировать с гиперпараметрами, например, с количеством деревьев или максимальной глубиной.\n",
    "\n",
    "#### 3. Общие рекомендации:\n",
    "\n",
    "- Несмотря на переобучение Random Forest, алгоритм оказался очень мощным на данном наборе данных.\n",
    "\n",
    "- Логистическая регрессия требует дополнительной оптимизации.\n",
    "\n",
    "- Также стоит дополнительно протестировать на других данных и провести оценку с помощью кросс-валидации, чтобы убедиться в стабильности результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1d6624-2fd9-4dff-bbe4-0aa43e02bc73",
   "metadata": {},
   "source": [
    "### f. Добавить техники из улучшенного бейзлайна (пункт 3c)\n",
    "На основе пункта 3c улучшения бейзлайна, мы можем применить следующие техники:\n",
    "\n",
    "#### 1. Подбор гиперпараметров:\n",
    "\n",
    "Используем GridSearchCV или RandomizedSearchCV для поиска оптимальных гиперпараметров моделей, таких как количество деревьев в Random Forest или коэффициент регуляризации в логистической регрессии.\n",
    "\n",
    "#### 2. Аугментация данных:\n",
    "\n",
    "Для задач классификации на табличных данных можно использовать методы увеличения объема данных через генерацию новых примеров, например, с помощью SMOTE (Synthetic Minority Over-sampling Technique) для балансировки классов.\n",
    "\n",
    "#### 3. Использование ансамблей:\n",
    "\n",
    "Мы можем объединить несколько моделей для улучшения стабильности и обобщающей способности (например, через Bagging или Boosting)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eaf7d4-ffe9-4319-9531-510be5d04ca8",
   "metadata": {},
   "source": [
    "#### Пример добавления аугментации данных через SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a66d6924-71f4-4f5a-a600-aaa09fa84072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Применяем SMOTE для балансировки классов\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b0c56c-ee03-4658-b48b-ada60b7c820c",
   "metadata": {},
   "source": [
    "#### Пример использования GridSearchCV для подбора гиперпараметров для Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f08b8022-3b0a-4748-ab7c-f11d14b3046e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Подбор гиперпараметров для Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, n_jobs=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Лучшие гиперпараметры:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a79270-ea10-4794-b20a-bf1cffe2d858",
   "metadata": {},
   "source": [
    "### g. Обучить модели для выбранных наборов данных\n",
    "После добавления улучшений из бейзлайна, теперь необходимо обучить модели на данных с применением этих техник. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adb6faaf-2c4b-4348-aa3c-3ca9c4dffd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие гиперпараметры для Logistic Regression: {'C': 10, 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Подбор гиперпараметров для Logistic Regression\n",
    "param_grid_log_reg = {\n",
    "    'C': [0.1, 1, 10],  # Регуляризация\n",
    "    'solver': ['liblinear', 'saga']  # Решатели для логистической регрессии\n",
    "}\n",
    "\n",
    "grid_search_log_reg = GridSearchCV(LogisticRegression(max_iter=2000), param_grid_log_reg, cv=5)\n",
    "grid_search_log_reg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Лучшие гиперпараметры для логистической регрессии\n",
    "print(\"Лучшие гиперпараметры для Logistic Regression:\", grid_search_log_reg.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a295613-a55e-4896-8aee-5771db17790a",
   "metadata": {},
   "source": [
    "### h. Оценить качество моделей по выбранным метрикам на выбранном наборе данных\n",
    "После того как модели обучены, нужно оценить их по метрикам Accuracy и F1 Score на тестовом наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d360695a-4b65-434b-90ae-e80a6d5f6887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (с улучшениями) Accuracy: 0.7666666666666667\n",
      "Logistic Regression (с улучшениями) F1 Score: 0.6995370370370371\n",
      "Random Forest (с улучшениями) Accuracy: 0.9666666666666667\n",
      "Random Forest (с улучшениями) F1 Score: 0.9616666666666667\n"
     ]
    }
   ],
   "source": [
    "# Прогнозы для логистической регрессии\n",
    "y_pred_log_reg_resampled = log_reg.predict(X_test)\n",
    "acc_log_reg_resampled = accuracy_score(y_test, y_pred_log_reg_resampled)\n",
    "f1_log_reg_resampled = f1_score(y_test, y_pred_log_reg_resampled, average='weighted')\n",
    "\n",
    "# Прогнозы для Random Forest\n",
    "y_pred_rf_resampled = rf.predict(X_test)\n",
    "acc_rf_resampled = accuracy_score(y_test, y_pred_rf_resampled)\n",
    "f1_rf_resampled = f1_score(y_test, y_pred_rf_resampled, average='weighted')\n",
    "\n",
    "print(\"Logistic Regression (с улучшениями) Accuracy:\", acc_log_reg_resampled)\n",
    "print(\"Logistic Regression (с улучшениями) F1 Score:\", f1_log_reg_resampled)\n",
    "print(\"Random Forest (с улучшениями) Accuracy:\", acc_rf_resampled)\n",
    "print(\"Random Forest (с улучшениями) F1 Score:\", f1_rf_resampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ec1be0-81ec-4374-abd8-b58dc6980a65",
   "metadata": {},
   "source": [
    "### i. Сравнить результаты моделей в сравнении с результатами из пункта 3\n",
    "Сравниваем результаты имплементированных моделей после применения техник улучшения бейзлайна с результатами из пункта 3.\n",
    "\n",
    "- Logistic Regression не изменила свои показатели, несмотря на подбор гиперпараметров. Это может свидетельствовать о том, что изначальная модель уже была достаточно оптимизирована или её возможности ограничены при данной задаче.\n",
    "\n",
    "- Random Forest, напротив, показал небольшое снижение Accuracy и F1 Score. Это может быть связано с переобучением исходной модели. После введения улучшений модель стала более обобщённой, что немного снизило точность, но сделало модель более надёжной."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a6956e-29d3-498c-b71c-b8ef19088a32",
   "metadata": {},
   "source": [
    "### j. Выводы\n",
    "1. Логистическая регрессия осталась на прежнем уровне после подбора гиперпараметров. Это говорит о том, что изначальные параметры уже давали оптимальный результат, либо модель ограничена в своей выразительности.\n",
    "\n",
    "2. Random Forest после улучшений показал более реалистичные и устойчивые результаты. Хотя точность немного снизилась, это компенсируется снижением переобучения и более устойчивым качеством предсказаний.\n",
    "\n",
    "3. Улучшения, предложенные в пункте 3с, оказали заметное влияние на качество модели Random Forest, что подтверждает необходимость использования техник предварительной обработки данных, балансировки классов и подбора гиперпараметров.\n",
    "\n",
    "Таким образом, улучшения из бейзлайна (пункт 3с) полезны и эффективны, особенно в сочетании с мощными ансамблевыми методами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566413b-8e9c-4afd-833e-c5ef471bb659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
